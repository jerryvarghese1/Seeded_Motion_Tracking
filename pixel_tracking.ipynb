{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d40261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import turtle\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "\n",
    "file = 'IMG_2509.MOV'\n",
    "folder = './videos/' \n",
    "fileid = folder+file\n",
    "\n",
    "# Takes two frames, calculates the phase cross correlation between them and outputs displacement\n",
    "@njit\n",
    "def calcdisp(imshape, frame2, frame1):       \n",
    "    center = imshape/2 # find center\n",
    "    bound_box_x = int(center[0]/2)-1 # setup for initial bounding box\n",
    "    bound_box_y = int(center[1]/2)-1\n",
    "    \n",
    "    # Consider an internal subset of the frame so that edge cases do not occur\n",
    "    smaller_prev_frame = frame1[int(center[0] - bound_box_x): int(center[0] + bound_box_x), int(center[1] - bound_box_y): int(center[1] + bound_box_y)]\n",
    "    \n",
    "    peaks_init = np.where(smaller_prev_frame == np.amax(smaller_prev_frame)) # find peaks in subset image\n",
    "    peaks_init = [peaks_init[1][0] + bound_box_y, peaks_init[0][0] + bound_box_x] # transform pixel locations for compatibility with the larger image\n",
    "    \n",
    "    search_pix = 10 # considers a 20 x 20 pixel box around the peak\n",
    "    \n",
    "    # subset both frames into very localized regions considering the movement of only one pixel\n",
    "    neighbor_search2 = frame2[int(peaks_init[1] - search_pix): int(peaks_init[1] + search_pix), int(peaks_init[0] - search_pix): int(peaks_init[0] + search_pix)]\n",
    "    neighbor_search1 = frame1[int(peaks_init[1] - search_pix): int(peaks_init[1] + search_pix), int(peaks_init[0] - search_pix): int(peaks_init[0] + search_pix)]\n",
    "    \n",
    "    # find peaks\n",
    "    peaks2 = np.where(neighbor_search2 == np.amax(neighbor_search2))\n",
    "    peaks1 = np.where(neighbor_search1 == np.amax(neighbor_search1))\n",
    "    \n",
    "    # store peaks\n",
    "    peaks2 = [peaks2[1][0], peaks2[0][0]]\n",
    "    peaks1 = [peaks1[1][0], peaks1[0][0]]\n",
    "    \n",
    "    peaks2 = np.array(peaks2)\n",
    "    peaks1 = np.array(peaks1)\n",
    "    \n",
    "    # calculate displacement\n",
    "    disp = peaks2 - peaks1\n",
    "    \n",
    "    tmp = list(disp)\n",
    "    \n",
    "    # filter\n",
    "    if abs(tmp[0]) > 10:\n",
    "        tmp[0] = 0\n",
    "    if abs(tmp[1]) > 10:\n",
    "        tmp[1] = 0\n",
    "        \n",
    "    return tmp\n",
    "\n",
    "vid = cv2.VideoCapture(0) # Starts video capture object\n",
    " \n",
    "# Initializations\n",
    "iteration = 0 \n",
    "prevFrame = 0\n",
    "\n",
    "dstep = np.empty([1,2])\n",
    "totD= np.array([[0,0]])\n",
    "time = [0]\n",
    "start = timer()\n",
    "\n",
    "\n",
    "#gpuframe1 = cv2.cuda_GpuMat() (Could not get gpu acceleration to work)\n",
    "#gpuframe2 = cv2.cuda_GpuMat()\n",
    "\n",
    "currentLoc = turtle.Turtle() # Initializes turtle for visualization\n",
    "turtle.setup(width=300, height=300, startx=0, starty=0)\n",
    "cap = cv2.VideoCapture(fileid)\n",
    "\n",
    "while(True):\n",
    "    # Capture the video frame by frame\n",
    "\n",
    "    ret, frame = cap.read() # get frame\n",
    "\n",
    "    #frameShape = frame.shape #?\n",
    "     \n",
    "    im = cv2.resize(frame, None, fx=.25, fy=.25) # decimate quality of image by resizing\n",
    "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV) \n",
    "    \n",
    "    lower_blue = np.array([36,140,140])\n",
    "    upper_blue = np.array([86,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    res = cv2.bitwise_and(im,im, mask= mask)\n",
    "    proc_im = cv2.cvtColor(res, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "      \n",
    "    bw_img = cv2.cvtColor(np.float32(proc_im), cv2.COLOR_RGB2GRAY) # convert to grayscale\n",
    "    \n",
    "    imshape = np.array(bw_img.shape)\n",
    "#    gpuframe1.upload(bw_img) (gpu acceleration, doesn't work)\n",
    "   \n",
    "    if iteration > 3 and iteration <= 15: # waits till there are sufficient frames to calculate\n",
    "        calcdisp(imshape, bw_img, prevFrame)\n",
    "    if iteration > 15: # allows program to 'warm up'. In initial tests, initial measurements were not accurate\n",
    "        tmp = calcdisp(imshape, bw_img, prevFrame) # raw displacement data\n",
    "        dstep = np.vstack((dstep, tmp)) # stacks the displacement step data just recieved\n",
    "        time = np.vstack((time, timer()-start)) # stacks the time data\n",
    "        \n",
    "        \n",
    "        totD = np.vstack((totD, np.sum(dstep, axis=0))) # sums displacement steps to calculate total displacement\n",
    "        \n",
    "        # updates turtle\n",
    "        currentLoc.sety(totD[iteration-15, 1]*.35)\n",
    "        currentLoc.setx(totD[iteration-15, 0]*.35)\n",
    "        \n",
    "    prevFrame = bw_img # sets current frame as previous frame\n",
    "#    gpuframe2.upload(prevFrame)\n",
    "    iteration = iteration + 1 #increases iteration\n",
    "\n",
    "#    print(iteration,timer()-start) # prints time (for debugging/optimization purposes)\n",
    "    cv2.imshow('frame2',res)\n",
    "    cv2.imshow('frame3', im)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the capture object\n",
    "\n",
    "vid.release()\n",
    "\n",
    "# Destroy all the windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
